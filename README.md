Vrazum is a LLM aggregator with optimized use of different models in different contexts windows. Currently supported providers include ChatGPT (OpenAI), Claude (Anthropic), Deepseek, Grok (X) and Gemini (Google). Vrazum is project-management oriented platform to harness LLM models in shared workspaces. The Home page displays general introduction for new users. 

At the beginning new users can chat without project selections. Some key features however require the creation of new project or joining to existing project. Interactions without project interactions include:

- LLM chat with LLM selection, customizable prompt shortcuts and bookmarking options. AI selection provides options for available options. Provider selection asks API key. API keys are encrypted into the store. With provider keys the user can retrieve a model selection modal and select between available models. The default model is always previously selected model. Prompt shortcuts allow user to save and edit prompt shortcuts used for responses. 
- LLM thread sidebar to create, select, delete, sort, filter and search threads.
- Project selector in header to have access to change and add projects in any context window. 
- Saving and retrieval of bookmarked chat messages
- P2P messaging in LLM context. LLM responses can be deactivated for allowing stakeholder discussion. This allows to allocate the interaction frequency to desirable patterns. Toggling options include deactivation without conditions, response after x number of human messages, and maximum token usage. LLM responses summarize previous discussion by text output or selectable prompt buttons. 
- User profile section to manage settings and follow up the personal progression. Part of collaborative features include follow interactions between users to fetch interesting content in home feed. 
- Theme switcher with various options.
- Language switcher which currently supports English and Russian. 


Scheduled features for further updates include:
- AI agent support to generate client agents based on retrieved context. The formation of agents is planned to utilize the thread context with retrieval of messaging progression. These options could include the use of chat summarization messages, liked or bookmarked messages, and applied prompt shortcuts and selections. One of key aspects of AI agents is that they must have access to navigate between allowed workspaces and have access to critical data and tools. This allows agents to provide constant automated support for handling routine queries, use hyper personalizations to mimic the behavior of work duties, as well as synchronization of stakeholder consistency. 
- Chat window timeline for allowing step-oriented navigation in a thread. Anchoring can be based on LLM summarization messages or consensus voting events, for instance. 
- Home feed to display achievements and progression of connections. This is particularly useful for passive users who are only seeking to view and comment user actions. 
- Model favorites to toggle faster between models.
- Notes page to script-based processing of user notes and documents. This space connected with different projects allows to formalize LLM outputs but also provide additional context for LLM. The interaction style will resemble somewhat how Co-Pilot operates.
- Agent navigator page for visual scripting and inspection of agent architectures. Unlike in LLM chat, here the intreaction does rely on mouse and gesture interactions instead of manual text inputs.